kind: ConfigMap
apiVersion: v1
metadata:
  name: spark-default-config
  namespace: spark-datamesh-demo
  uid: 7e76c52e-6d33-455f-95ca-0316a0c6102e
  resourceVersion: '74175324'
  creationTimestamp: '2024-05-29T18:16:35Z'
  managedFields:
    - manager: kubectl-create
      operation: Update
      apiVersion: v1
      time: '2024-05-29T18:16:35Z'
      fieldsType: FieldsV1
      fieldsV1:
        'f:data': {}
    - manager: Mozilla
      operation: Update
      apiVersion: v1
      time: '2024-06-04T18:37:26Z'
      fieldsType: FieldsV1
      fieldsV1:
        'f:data':
          'f:spark-defaults.conf': {}
data:
  spark-defaults.conf: >
    spark.sql.defaultCatalog apm

    spark.sql.catalog.apm.type hive

    spark.sql.catalog.apm.uri thrift://hive-metastore:9083

    # Example spark-defaults.conf

    spark.executor.instances 2

    spark.executor.memory 4g

    spark.executor.cores 2

    spark.driver.memory 2g

    spark.driver.cores 1

    spark.sql.catalog.apm org.apache.iceberg.spark.SparkCatalog

    iceberg.engine.hive.enabled true

    spark.sql.defaultCatalog apm

    spark.sql.catalog.apm.type hive

    spark.sql.catalog.apm.uri thrift://hive-metastore:9083

    spark.hadoop.hive.metastore.schema.verification false

    spark.hadoop.hive.metastore.schema.verification.record.version false

    spark.sql.catalog.apm.io-impl org.apache.iceberg.aws.s3.S3FileIO

    spark.sql.catalog.apm.warehouse s3a://datamesh/observability/

    spark.sql.catalog.apm.s3.endpoint
    https://minio-api-datamesh-demo.apps.rosa-8grhg.ssnp.p1.openshiftapps.com

    spark.sql.extensions
    org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

    spark.eventLog.enabled true 

    spark.eventLog.dir s3a://spark-events/logs/

    spark.history.fs.logDirectory s3a://spark-events/logs/

    spark.hadoop.fs.s3a.endpoint
    https://minio-api-datamesh-demo.apps.rosa-8grhg.ssnp.p1.openshiftapps.com

    spark.hadoop.fs.s3a.secret.key minio1234 

    spark.hadoop.fs.s3a.access.key minioAdmin 

    spark.hadoop.fs.s3a.path.style.access true

    spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem

    spark.sql.storeAssignmentPolicy ANSI

    spark.ui.enabled true

    spark.sql.connect.enable true

    spark.sql.connect.port 15002
